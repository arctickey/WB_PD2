---
title: "Prezentacja metodologii"
author: "Jan Borowski, Filip Chrzuszcz, Piotr Fic"
date: "14 05 2020"
output: ioslides_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Kodowanie zmiennych kategorycznych

Uzupełnione zbiory danych zawierają wiele zmiennych kategorycznych. Podejścia odrzucone:

- one-hot encoding
- ordinal encoding

Wybrane rozwiązanie:

- target encoding

Metoda kodowania jest uniwersalna i powszechnie używana.  
Dodatkowo usunięto w kilku zbiorach zmienne, które zawierały
bardzo dużo unikalnych wartości.

## Schemat kodowania zmiennych kategorycznych

- Zbiór podzielony na część treningową i testową
- Wyliczenie parametrów **target encoding** na zbiorze treningowym
- Kodowanie zmiennych w obu zbiorach

## Narzędzie do kodowania

Pakiet [H<sub>2</sub>O](https://docs.h2o.ai/h2o/latest-stable/h2o-docs/index.html) napisany w języku Java, udostępniający API
dla R i python. Wykorzystuje obliczenia wielowątkowe. Kompletne narzędzie do
uczenia maszynowego.  
Użyty moduł do target encoding:  

- dodanie szumu 
- średnie ważone względem liczności grup

## Wybrane algorytmy

Zbiory danych są gotowe do użycia przez modele uczenia maszynowego.  
Wykorzystane modele (*mlr name*):

- **regresja logistyczna**: *classif.glmnet*
- **las losowy**: *classif.ranger*
- **SVM**: *classif.svm*
- **XGBoost**: *classif.xgboost*

## Ewaluacja modeli

<center>
![](schemat.png)
</center>

## Wyniki
Zdecydowaliśmy się na użycie dwóch miar skuteczności algorytmów: F1 score oraz Accuracy. Te dwie miary dobrze się uzupełniają, gdyż pozwalają dobrze zmierzyć skuteczności naszych imputacji oraz algorytmów zarówno na zbiorach zbalansowanych, jak i niezbalansowanych.

## Rozkład miary F1

```{r echo=FALSE, message=FALSE,warning=FALSE}
library(ggplot2)
library(tidyverse)
data <- read_csv('./wyniki_csv/RESULT.csv')
p<-ggplot(data, aes(x=method, y=F1, color=method)) +
  geom_boxplot()+theme_minimal()+labs(x="",y="")+ggtitle("Wyniki średnie F1")
p

```

## Odchylenie standardowe F1

```{r echo=FALSE, message=FALSE,warning=FALSE}
knitr::kable(data %>% group_by(method) %>% summarise(F1_std=sd(F1,na.rm=TRUE)))
```

## Rozkład miary Accuracy

```{r echo=FALSE, message=FALSE,warning=FALSE}


p1<-ggplot(data, aes(x=method, y=acc, color=method)) +
  geom_boxplot()+theme_minimal()+labs(x="",y="")+ggtitle("Wyniki średnie accuracy")

p1
```

## Odchylenie standardowe Accuracy

```{r echo=FALSE, message=FALSE,warning=FALSE}
knitr::kable(data %>% group_by(method) %>% summarise(acc_std=sd(acc,na.rm=TRUE)))
```

## 

Na podstawie tych wykresów można wnioskować o ogólnych wynikach, jednkaże nie można się nimi sugerować zbyt bardzo, gdyż wyniki uzyskane przez algorytmy rożnią się w zależności od trudności zbioru a także od użytego algorytmu uczenia maszynowego. Sprawdźmy więc jak wyniki F1 różnią się w zależności od rodzaju imputacji oraz użytego algorytmu.


##

```{r echo=FALSE, message=FALSE,warning=FALSE}
data1 <- data %>% group_by(method,algorithm) %>% summarise(F1_mean=mean(F1,na.rm=TRUE))


p2<-ggplot(data1, aes(x=method, y=F1_mean, color=algorithm)) +
  geom_boxplot()+theme_minimal()+labs(x="",y="")+ggtitle("Wyniki F1 pośród róznych algorytmów oraz imputacji")
p2

```


## Ranking metod

Jako bardziej wiarygodną próbę oceny skuteczności imputacji spróbujmy uszeregować je wedle następującego schematu. Weźmy wynik każdej z metod imputacji na każdym ze zbiorów. Wynik taki definiujemy jako średnia ze wszystkich algorytmów uczenia maszynowego puszczonych na danym zbiorze przy danej imputacji. Następnie sortujemy wynik od najwyższego i przyznajemy algorytmom punkty za każde miejsce. Końcowo punkty sumujemy a ta metoda imputacji, która punktów uzyska najmniej wygrwa nasz ranking.


##

```{r echo=FALSE, message=FALSE,warning=FALSE}
data[is.na(data)] <- 0
data3 <- data %>% group_by(dataset,method) %>% summarise(mean=mean(acc,na.rm=TRUE))
order_scores <- data3 %>% group_by(dataset) %>% mutate(good_ranks = order(order(mean, decreasing=TRUE)))
order_scores1 <- order_scores %>% group_by(method) %>% summarise(wynik = sum(good_ranks))
order_scores1
```