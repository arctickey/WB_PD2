## Title of the article

*Authors: Jan Borowski, Filip Chrzuszcz, Piotr Fic  (Warsaw University of Technology)*

### Abstract

Missing observations in datasets used in machine learning models is a common and difficult problem. Most implementations of machine learning models, available in popular packages, are not prepared to deal with missing values. This requires user pre-processing of data. There are many suggestions to deal with this problem. Some solutions have been automated and are offered in publicly available packages for the R language. In our study, we tried to compare the quality of different methods of data imputation and their impact on the performance of machine learning models.\
...

### Introduction and Motivation

#### Definition of missing data

In the field of machine learning, one of the key objects is the data set. Real-world data are often incomplete, which prevents the use of many algorithms. Before creating a machine learning model, it is essential to solve the problem of missing observations. At the beginning, claryfing the definition of missing data is necessary. Missing data means that one or more variables have no data values in observations. This can be caused by various reasnons, which we can formally define as follows:

- MCAR (Missing completely at random)\
Values are missing completely at random if the events that lead to lack of value are independent both of observable variable and of unobservable parameters. The missing data are simply a random subset of the data. Analysis performed on MCAR data is unbiased, howewer data are rarely MCAR.
- MAR (Missing at random)\
Missingness of the values can be fully explained by complete variables. In other words, missing data are not affected by their characteristic, but are related to some or all of observed data. This is the most common assumption about missing data.
- MNR (Missing not at random)\
When data are missing not at random, the missingness is related to the characteristic of variable itself.

#### Techniques of dealing with missing data

In case of preparing a data set for machine learning models we can generally distinguish two approaches. The first method is **omission**. From the data set we can remove observations with at least one missing value or we can remove whole variables where missing values are present. This strategy is appropriate if the features are MCAR. However, it is frequently used also when this assumption is not met. It is also useless when the percentage of missing values is high. The second approach is **imputation**, where values are filled in the place of missing data. There are many methods of imputation, which we can divide into two groups. **Single imputation** techniques use information of one variable with missing values. Popular method is filling missings with mean, median or mode of no missing values. More advanced are predictions from regression models which are applied on the mean and covariance matrix estimated by analysis of complete cases. The main disadvatage of single imputation is treating the imputed value as true value. This method does not take into account the uncertainty of the missing value prediction. For this reason **multiple imputation** was proposed. This method imputes *k* values, which leads to creating *k* complete data sets. The analysis or model is applied on each complete data set and finally results are consolidated. This approach keeps the uncertainty about the range of values which the true value 
could have taken. Additionally, multiple imputation can be used in both cases of MCAR and MAR data.

### Related Work


### Methodology

For test purposes we used 9 dataset form OpenMl library ,available here https://www.openml.org/search?type=data. Every datasets are designed for binary classification and most of them contains numerical and categorical features.  

Before imputacien datasets are prepared. Preperation are diffrent for each dataset but always include:
<ol>
<li>Checking for typos and correcting them.</li>
<li>Categorical veriable are convert to lowercase if it's reduce number of unique categories.</li>
<li>Removing columns if it isnt containing any information (for example all observation have the same value).</li>
<li>Features like date or location are transform to help algoritm understand them (date for example is splited to three column 'year' , 'day' , 'month').</li>
</ol>

From prepered datasets we remove target varible and split dataset to train and test sets in proportion 4/1 respectively. Split is perform coplytly random and stay the same for all types of imputation. Missing data are imputed separately for train and test set.\
First we use Mode/median inputation where every categorical varible is imputed by mode and every numeric by median. It is very simple methode and its use as base result for more complex algoritm to imporve.\
SoftImput package works only for numeric features to compere theme with othere algoritm on the same data we use SoftImput for numeric variable and mode for categorical variable. Alternativly its posible to use SoftImput for numeric featurs and some othere algoritm for categorical but we decided this approach can lead to unreliable results.\
MissForest algoritm can be use on both numeric and categorical featues and can perform imputation without help of other methods.\
Inputation method from Mice package alsow can be run on all types of data.\
Iterative Robust Model-Based Imputation method form VIM package can impute all types of data. This method additionally create new columns with informacion whether observation was imputed or was't. We decidet to dont use this columns becouse other methods dont create them.\
Last method which we used is missMDA alsow can be use to impute numeric and categorical features.\
After imputation we add back target varibale to both sets.

To make prediction we use 'classif.rpart' method form mrl packege. It's inplementation of Decision Tree algorithm thats mean dataset dont required encoding becouse decision tree acept categoricar variables. To evaluated imputation method, classifier was trained on train set end test on test set. In this experiment we skip cross-validation step decision tree used default parametrs. For model evaluation we used 4 diffrent metric accuracy,AUC,precison and reccal. Most important was precison and reccal becouse some of datasets was vary unblanced. 
### Results


### Summary and conclusions 


